{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of rnn_shakesphere.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsThuVqnSm_C"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm8G8H6idfwE"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z05dYK24eWmI",
        "outputId": "6e829f1a-dc4b-4af1-c6b1-d85b528addbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = open('shakespeare_input.txt', 'rb').read().decode(encoding='utf-8')\n",
        "print('Total unique charachter: ',len(set(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique charachter:  67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUVCGSp4fJG1"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MciqPzecfKK1"
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69P0AlJ4fJ__"
      },
      "source": [
        "seq_length = 100\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vg4fcqFfJ3v"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Wdv0pAQCr1"
      },
      "source": [
        "Creating Data set for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbu-icIrfJ0y",
        "outputId": "d19e206d-dbd3-4a9a-ba15-99f53b0ddf48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "742YomoYfJyg"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS_4bOEtwems"
      },
      "source": [
        "GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAPVDcoxfJvn",
        "outputId": "155913f3-a82b-49c8-87b4-083bc0bf3e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)\n",
        "  \n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (64, None, 256)           17152     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (64, None, 67)            68675     \n",
            "=================================================================\n",
            "Total params: 4,024,131\n",
            "Trainable params: 4,024,131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa7737YmfJa0"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUzAjvGXfJYz"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir_gru = './training_checkpoints_gru'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir_gru, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2wkwkDWfJUb",
        "outputId": "fc2b2b21-772e-4c2d-ef9d-9871e4e145dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=10, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "707/707 [==============================] - 41s 58ms/step - loss: 1.9910\n",
            "Epoch 2/10\n",
            "707/707 [==============================] - 43s 60ms/step - loss: 1.4603\n",
            "Epoch 3/10\n",
            "707/707 [==============================] - 42s 59ms/step - loss: 1.3628\n",
            "Epoch 4/10\n",
            "707/707 [==============================] - 42s 60ms/step - loss: 1.3169\n",
            "Epoch 5/10\n",
            "707/707 [==============================] - 42s 60ms/step - loss: 1.2859\n",
            "Epoch 6/10\n",
            "707/707 [==============================] - 42s 60ms/step - loss: 1.2617\n",
            "Epoch 7/10\n",
            "707/707 [==============================] - 42s 60ms/step - loss: 1.2419\n",
            "Epoch 8/10\n",
            "707/707 [==============================] - 42s 60ms/step - loss: 1.2245\n",
            "Epoch 9/10\n",
            "707/707 [==============================] - 42s 60ms/step - loss: 1.2097\n",
            "Epoch 10/10\n",
            "707/707 [==============================] - 42s 60ms/step - loss: 1.1963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2KlVUAUxz4E"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGQLkchwx6y0",
        "outputId": "dd913180-9fac-4a07-ef0a-c7b5fefc25bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)\n",
        "  \n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.backward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.forward_layer.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.backward_layer.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (64, None, 256)           17152     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (64, None, 67)            68675     \n",
            "=================================================================\n",
            "Total params: 5,332,803\n",
            "Trainable params: 5,332,803\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft7UxUktyO-H"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbRNfYNByPEx"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir_lstm = './training_checkpoints_lstm'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir_lstm, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8O1TvQRyPNH",
        "outputId": "e2dbdf8f-2d71-47ec-91a9-c569c4b8a6d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=10, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "707/707 [==============================] - 52s 74ms/step - loss: 1.9859\n",
            "Epoch 2/10\n",
            "707/707 [==============================] - 52s 74ms/step - loss: 1.4526\n",
            "Epoch 3/10\n",
            "707/707 [==============================] - 53s 75ms/step - loss: 1.3484\n",
            "Epoch 4/10\n",
            "707/707 [==============================] - 53s 75ms/step - loss: 1.2979\n",
            "Epoch 5/10\n",
            "707/707 [==============================] - 53s 75ms/step - loss: 1.2639\n",
            "Epoch 6/10\n",
            "707/707 [==============================] - 53s 75ms/step - loss: 1.2371\n",
            "Epoch 7/10\n",
            "707/707 [==============================] - 53s 75ms/step - loss: 1.2140\n",
            "Epoch 8/10\n",
            "707/707 [==============================] - 53s 75ms/step - loss: 1.1929\n",
            "Epoch 9/10\n",
            "707/707 [==============================] - 53s 75ms/step - loss: 1.1733\n",
            "Epoch 10/10\n",
            "707/707 [==============================] - 53s 75ms/step - loss: 1.1540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vbjOYE6x2Su"
      },
      "source": [
        "Bidirectional_LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehudtTG4x7jr",
        "outputId": "81e6d3fb-5839-4ed6-b81d-35e5b850f9da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    \n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform')),\n",
        "                               \n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)\n",
        "  \n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (64, None, 256)           17152     \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (64, None, 2048)          10493952  \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (64, None, 67)            137283    \n",
            "=================================================================\n",
            "Total params: 10,648,387\n",
            "Trainable params: 10,648,387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UFEof0CzIPk"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmbMwi6OzIeS"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir_bd_lstm = './training_checkpoints_bd_lstm'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir_bd_lstm, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohi9PtZd10Qr",
        "outputId": "1070a887-55c3-468d-a631-348e09004b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "history = model.fit(dataset, epochs=10, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "707/707 [==============================] - 102s 144ms/step - loss: 0.2955\n",
            "Epoch 2/10\n",
            "707/707 [==============================] - 102s 144ms/step - loss: 0.0515\n",
            "Epoch 3/10\n",
            "707/707 [==============================] - 102s 144ms/step - loss: 0.0450\n",
            "Epoch 4/10\n",
            "707/707 [==============================] - 102s 145ms/step - loss: 0.0411\n",
            "Epoch 5/10\n",
            "707/707 [==============================] - 103s 145ms/step - loss: 0.0384\n",
            "Epoch 6/10\n",
            "707/707 [==============================] - 102s 145ms/step - loss: 0.0361\n",
            "Epoch 7/10\n",
            "707/707 [==============================] - 102s 145ms/step - loss: 0.0339\n",
            "Epoch 8/10\n",
            "707/707 [==============================] - 102s 145ms/step - loss: 0.0320\n",
            "Epoch 9/10\n",
            "707/707 [==============================] - 102s 145ms/step - loss: 0.0302\n",
            "Epoch 10/10\n",
            "707/707 [==============================] - 102s 145ms/step - loss: 0.0282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CINCf0-90rQd"
      },
      "source": [
        "Text generation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-u-Lb1i1ARD"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  \n",
        "  num_generate = 1000\n",
        "\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  \n",
        "  temperature = 1.0\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    \n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkXkoK-J1TqP"
      },
      "source": [
        "GRU TEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTFkiKN9IlVo",
        "outputId": "32a8d193-373c-4b4f-8766-a4e2929a190b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir_gru)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints_gru/ckpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j_AflQmfJPc",
        "outputId": "550eaa9a-3579-404b-d9f5-34273bdaac9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir_gru))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "print(generate_text(model, start_string=u\"R\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROKE:\n",
            "How fair noteowledge in one shere,\n",
            "That thy face\n",
            "I stand on mere his shame, obedient child;\n",
            "Who, this is the story, show me of this eagle\n",
            "in thy mother's penal death.\n",
            "\n",
            "DROMIO OF OLYO:\n",
            "When must my househfend give troce.\n",
            "\n",
            "VESTOR:\n",
            "And to thy bones this charge about within a man shall find\n",
            "Him sup against your majesty, he came\n",
            "Richard by the season on: yet, to feed up\n",
            "Is three monks you have done any deep die.\n",
            "\n",
            "FABIAN:\n",
            "I am Flanderer.\n",
            "\n",
            "SIR ANDREW:\n",
            "If you must encounter it a verk so dole!\n",
            "\n",
            "PISTOL:\n",
            "Is'tiniar?\n",
            "\n",
            "GLOUCESTER:\n",
            "Yes, my sweet Prince Paris, which has deliver'd ye and not dework in't. By yond a\n",
            "marriage-voice to the gentle crab-treads of your thoughts:\n",
            "Your grace is meeting, and at merry jests.\n",
            "\n",
            "FALSTAFF:\n",
            "Go certhinks to mine honour,\n",
            "My true mothers have shut all; and not that diviner:\n",
            "If by heaven, till you had attain'd.\n",
            "\n",
            "LUCIANA:\n",
            "Poins!\n",
            "USALINE:\n",
            "I will or sorrow up.\n",
            "\n",
            "VALENTINE:\n",
            "Path new time to twain,\n",
            "And the ming can bring them,\n",
            "When instruments the thibted scorrage:\n",
            "In fait\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXrTgoYn1_8M"
      },
      "source": [
        "LSTM TEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA2_EGGX2AIH",
        "outputId": "4853866b-aa58-48be-bfa0-9e8b2076304b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir_lstm))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "print(generate_text(model, start_string=u\"R\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RUGENTER:\n",
            "I go to Juliet and be about thy entertainment.\n",
            "\n",
            "VIOLA:\n",
            "How has this? what names fair?\n",
            "\n",
            "AUTOLY:\n",
            "I am old, I should not thither stoop.\n",
            "\n",
            "First Playe:\n",
            "That he and\n",
            "I have been O for mine enemies, come to him, while none doth fright\n",
            "The insolence of Madam Silvia\n",
            "The greater fates of Maines, bus man, how all they want\n",
            "in lackey! I have done; I sweare a hundred colours\n",
            "With half dishonour to the groves, ithe swords,\n",
            "And like an imprescrieunce, when he is ne'er out of\n",
            "kisched with the cruelty; otherwise and counsel or stiff for heart and\n",
            "beard and appelet sold to picture of him: I say hanging himself.\n",
            "\n",
            "WESTMORELAND:\n",
            "Hed all the swelter creeping wings!\n",
            "\n",
            "PETERTI:\n",
            "We two will quickly find you.\n",
            "\n",
            "KING HENRY VI:\n",
            "Put it you, good Knight.\n",
            "\n",
            "Servant:\n",
            "By all is as many may help me:\n",
            "I have been sword on me; I should endure\n",
            "\n",
            "LAERTES:\n",
            "\n",
            "Third Secretled you are delivered,\n",
            "By all haste: well.\n",
            "\n",
            "SEBASTIAN:\n",
            "Doubt not yea, that he and my suit to thee,\n",
            "I shull fall England in which special eyes,\n",
            "A most disc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CImt8OHA2ASf"
      },
      "source": [
        "BIDIRECTIONAL LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ci1_erP2Acc",
        "outputId": "507a2d6e-61a2-4003-b7c2-1abb8941d286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir_bd_lstm))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "print(generate_text(model, start_string=u\"R\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RORORORORORORORORORORORORORORORORORORORORORORORORORORORORORORONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONONENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENENEN\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}