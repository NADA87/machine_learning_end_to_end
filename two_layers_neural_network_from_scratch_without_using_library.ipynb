{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "solution_assignment_4 - two layer neural network.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8ZS-ozwHQR1"
      },
      "source": [
        "# loading libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "from mlxtend.data import loadlocal_mnist\n",
        "import platform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joZr7l9LHQR-",
        "outputId": "919156ee-5644-4c83-dcd5-e2a839a9517e"
      },
      "source": [
        "# loading training data\n",
        "if not platform.system() == 'Windows':\n",
        "    X_train, y_train = loadlocal_mnist(\n",
        "            images_path='train-images-idx3-ubyte', \n",
        "            labels_path='train-labels-idx1-ubyte')\n",
        "\n",
        "else:\n",
        "    X_train, y_train = loadlocal_mnist(\n",
        "            images_path='train-images.idx3-ubyte', \n",
        "            labels_path='train-labels.idx1-ubyte'\n",
        "    )\n",
        "    \n",
        "if not platform.system() == 'Windows':\n",
        "    X_test, y_test = loadlocal_mnist(\n",
        "            images_path='train-images-idx3-ubyte', \n",
        "            labels_path='train-labels-idx1-ubyte')\n",
        "\n",
        "else:\n",
        "    X_test, y_test = loadlocal_mnist(\n",
        "            images_path='t10k-images.idx3-ubyte', \n",
        "            labels_path='t10k-labels.idx1-ubyte'\n",
        "    )\n",
        "    \n",
        "print(\"train shape: \",X_train.shape)\n",
        "print(\"test shape: \",X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape:  (60000, 784)\n",
            "test shape:  (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG3e_hVzHQSF"
      },
      "source": [
        "X_train=np.transpose(X_train)/256\n",
        "X_test=np.transpose(X_test)/256\n",
        "\n",
        "y_train=y_train.reshape(60000,1)\n",
        "y_train=np.transpose(y_train)\n",
        "\n",
        "y_test=y_test.reshape(10000,1)\n",
        "y_test=np.transpose(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8EyRhfkHQSM"
      },
      "source": [
        "enc = OneHotEncoder()\n",
        "y_train_transformed=enc.fit_transform(np.transpose(y_train)).toarray()\n",
        "y_train_transformed=np.transpose(y_train_transformed)\n",
        "\n",
        "y_test_transformed=enc.fit_transform(np.transpose(y_test)).toarray()\n",
        "y_test_transformed=np.transpose(y_test_transformed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CZzjIRMHQSS"
      },
      "source": [
        "# inializing parameters for L layer neural network\n",
        "def initialize_parameters(layers_neurons_list):\n",
        "    \n",
        "    total_layers=len(layers_neurons_list)\n",
        "    \n",
        "    parameters={}\n",
        "    \n",
        "    for i in range(1,total_layers):\n",
        "        parameters['w'+str(i)] = np.random.randn(layers_neurons_list[i],layers_neurons_list[i-1])/np.sqrt(layers_neurons_list[i-1])\n",
        "        parameters['b'+str(i)] = np.random.randn(layers_neurons_list[i],1)/np.sqrt(layers_neurons_list[i-1])\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_W7Q4hiHQSY"
      },
      "source": [
        "# feed forward  { hidden layer activation sigmoid and output layer activation softmax } \n",
        "\n",
        "def feed_forward(input_data,parameters):\n",
        "    \n",
        "    cache={}\n",
        "    cache['a'+str(0)]=input_data\n",
        "    temp=input_data\n",
        "    for i in range(1,int(len(parameters)/2)):\n",
        "        temp = np.dot(parameters['w'+str(i)],temp) + parameters['b'+str(i)]\n",
        "        cache['z'+str(i)]=temp\n",
        "        temp = 1/(1+np.exp(-temp))\n",
        "        cache['a'+str(i)]=temp\n",
        "        \n",
        "    temp =  np.dot(parameters['w'+str(int(len(parameters)/2))],temp) + parameters['b'+str(int(len(parameters)/2))] \n",
        "    cache['z'+str(int(len(parameters)/2))] = temp\n",
        "    output = np.exp(temp)/np.sum(np.exp(temp),axis=0) \n",
        "    cache['a'+str(int(len(parameters)/2))] = output\n",
        "    #cost=np.sum(-np.log(output)*labels)/labels.shape[1]\n",
        "    \n",
        "    return cache,output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKoztf-HQSe"
      },
      "source": [
        "def cost_cross_entropy(output,labels):\n",
        "    a=-np.log(output)*labels\n",
        "    return np.sum(a)/labels.shape[1]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wjF7EGFHQSo"
      },
      "source": [
        "def accuracy(x,y,para):\n",
        "    tuned_prob=feed_forward(x,para)[1]\n",
        "    max_arguments=np.argmax(tuned_prob,axis=0).reshape(1,tuned_prob.shape[1])\n",
        "    classified=np.zeros([tuned_prob.shape[0],tuned_prob.shape[1]])\n",
        "    for i in range(0,tuned_prob.shape[1]):\n",
        "        classified[max_arguments[0,i],i]=1\n",
        "    return (np.sum(classified*y)/y.shape[1])*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTqQgx13HQSu"
      },
      "source": [
        "def back_prop(cache,y,output,parameters):\n",
        "    \n",
        "    grad={}\n",
        "    total_layers = int(len(cache)/2)\n",
        "    \n",
        "    m = y.shape[1]\n",
        "    grad['dz'+str(total_layers)] = output-y\n",
        "    grad['dw'+str(total_layers)] = (1/m)*np.dot(grad['dz'+str(total_layers)],np.transpose(cache['a'+str(total_layers-1)]))\n",
        "    grad['db'+str(total_layers)] = (1/m)*np.sum(grad['dz'+str(total_layers)],axis=1).reshape(y.shape[0],1)\n",
        "    \n",
        "    for i in range(total_layers-1,0,-1):\n",
        "        grad['da'+str(i)] = np.dot(np.transpose(parameters['w'+str(i+1)]),grad['dz'+str(i+1)])\n",
        "        grad['dz'+str(i)] = grad['da'+str(i)] * cache['a'+str(i)] *(1-cache['a'+str(i)])\n",
        "        grad['dw'+str(i)] = (1/m)*np.dot(grad['dz'+str(i)],np.transpose(cache['a'+str(i-1)]))\n",
        "        grad['db'+str(i)] = (1/m)*np.sum(grad['dz'+str(i)],axis=1).reshape(grad['dz'+str(i)].shape[0],1)\n",
        "    \n",
        "    \n",
        "    #grad['dz'+str(total_layers)]= (1/m)*output-y\n",
        "    #grad['dw'+str(total_layers)]=(1/m)*np.dot(grad['dz'+str(total_layers)],np.transpose(cache['a'+str(total_layers-1)]))\n",
        "    #grad['db'+str(total_layers)]=(1/m)*np.sum(grad['dz'+str(total_layers)],axis=1).reshape(grad['dz'+str(total_layers)].shape[0],1)\n",
        "    \n",
        "    \n",
        "    \n",
        "   # for i in range(total_layers-1,0,-1):\n",
        "    #    grad['da'+str(i)] = (1/m)* np.dot( np.transpose(parameters['w'+str(i+1)]) , grad['dz'+str(i+1)]  )\n",
        "     #   grad['dz'+str(i)]= (1/m)*grad['da'+str(i)] * cache['z'+str(i)] *(1-cache['z'+str(i)])\n",
        "      #  grad['dw'+str(i)]=(1/m)*np.dot(grad['dz'+str(i)], np.transpose(cache['a'+str(i-1)])   )\n",
        "       # grad['db'+str(i)]=(1/m)*np.sum(grad['dz'+str(i)],axis=1).reshape(grad['dz'+str(i)].shape[0],1)\n",
        "        \n",
        "        \n",
        "    return grad\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu1ILMJGHQSz"
      },
      "source": [
        "def update_parameters(parameters,grad,learning_rate=0.01):\n",
        "    layers=int(len(parameters)/2)\n",
        "    for i in range(layers):\n",
        "        parameters['w'+str(i+1)] = parameters['w'+str(i+1)] - (learning_rate*grad['dw'+str(i+1)])\n",
        "        parameters['b'+str(i+1)] = parameters['b'+str(i+1)] - (learning_rate*grad['db'+str(i+1)])\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqO0z-iWHQS4"
      },
      "source": [
        "parameters=initialize_parameters([784,128,10])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1fgVUXdHQS9",
        "outputId": "babe061f-6b96-4090-cc41-c422855d8300"
      },
      "source": [
        "for epochs in range(1,450):\n",
        "    accu_train=accuracy(X_train,y_train_transformed,parameters)\n",
        "    accu_test=accuracy(X_test,y_test_transformed,parameters)\n",
        "    grad=back_prop(feed_forward(X_train,parameters)[0],y_train_transformed,feed_forward(X_train,parameters)[1],parameters)\n",
        "    cost=cost_cross_entropy(feed_forward(X_train,parameters)[1],y_train_transformed)\n",
        "    \n",
        "    update_parameters(parameters,grad,learning_rate=0.8)\n",
        "    print(\"epoch: \"+str(epochs)+\"-----\"+\"cost: \"+str(cost)+\"-----\"+\"accu_train: \"+str(accu_train)[:4]+\"-----accu_test: \"+str(accu_test)[:4]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1-----cost: 2.5830331683472085-----accu_train: 9.93-----accu_test: 10.3\n",
            "epoch: 2-----cost: 2.7971122673802262-----accu_train: 15.6-----accu_test: 16.1\n",
            "epoch: 3-----cost: 2.4647074982145156-----accu_train: 12.8-----accu_test: 13.0\n",
            "epoch: 4-----cost: 2.4569399905710427-----accu_train: 19.0-----accu_test: 19.4\n",
            "epoch: 5-----cost: 2.237219417339316-----accu_train: 26.5-----accu_test: 26.0\n",
            "epoch: 6-----cost: 2.1716324246643497-----accu_train: 24.2-----accu_test: 24.2\n",
            "epoch: 7-----cost: 2.0692252088740997-----accu_train: 28.6-----accu_test: 28.4\n",
            "epoch: 8-----cost: 2.00014635553658-----accu_train: 27.8-----accu_test: 28.0\n",
            "epoch: 9-----cost: 1.942968408187343-----accu_train: 36.9-----accu_test: 37.8\n",
            "epoch: 10-----cost: 1.861492864433213-----accu_train: 34.8-----accu_test: 34.9\n",
            "epoch: 11-----cost: 1.8147006299175499-----accu_train: 46.3-----accu_test: 47.0\n",
            "epoch: 12-----cost: 1.7293972122998107-----accu_train: 41.7-----accu_test: 42.5\n",
            "epoch: 13-----cost: 1.6895735515794676-----accu_train: 56.1-----accu_test: 56.3\n",
            "epoch: 14-----cost: 1.603698920891942-----accu_train: 48.1-----accu_test: 48.8\n",
            "epoch: 15-----cost: 1.5698609566325394-----accu_train: 62.2-----accu_test: 62.5\n",
            "epoch: 16-----cost: 1.4876356544641878-----accu_train: 53.3-----accu_test: 54.3\n",
            "epoch: 17-----cost: 1.4577039601503026-----accu_train: 65.4-----accu_test: 65.7\n",
            "epoch: 18-----cost: 1.384155236466412-----accu_train: 57.3-----accu_test: 58.6\n",
            "epoch: 19-----cost: 1.3544632622705706-----accu_train: 67.8-----accu_test: 68.0\n",
            "epoch: 20-----cost: 1.2916699064290078-----accu_train: 60.8-----accu_test: 61.8\n",
            "epoch: 21-----cost: 1.2586148656819032-----accu_train: 70.0-----accu_test: 70.3\n",
            "epoch: 22-----cost: 1.2046941797060302-----accu_train: 64.3-----accu_test: 65.7\n",
            "epoch: 23-----cost: 1.1674951153159827-----accu_train: 72.2-----accu_test: 72.9\n",
            "epoch: 24-----cost: 1.1218010319855618-----accu_train: 68.1-----accu_test: 69.3\n",
            "epoch: 25-----cost: 1.0824887938093382-----accu_train: 74.3-----accu_test: 75.2\n",
            "epoch: 26-----cost: 1.046446189637828-----accu_train: 71.4-----accu_test: 72.7\n",
            "epoch: 27-----cost: 1.0077863862223644-----accu_train: 75.8-----accu_test: 76.4\n",
            "epoch: 28-----cost: 0.9815993725752943-----accu_train: 74.1-----accu_test: 75.3\n",
            "epoch: 29-----cost: 0.9459982148207056-----accu_train: 76.5-----accu_test: 77.3\n",
            "epoch: 30-----cost: 0.9280546780347171-----accu_train: 75.8-----accu_test: 76.8\n",
            "epoch: 31-----cost: 0.8981344335228081-----accu_train: 76.7-----accu_test: 77.4\n",
            "epoch: 32-----cost: 0.885438677188078-----accu_train: 76.5-----accu_test: 77.2\n",
            "epoch: 33-----cost: 0.8651822668281337-----accu_train: 76.4-----accu_test: 77.1\n",
            "epoch: 34-----cost: 0.8512005140112032-----accu_train: 76.6-----accu_test: 77.3\n",
            "epoch: 35-----cost: 0.84318245948703-----accu_train: 76.6-----accu_test: 77.0\n",
            "epoch: 36-----cost: 0.8196399000485775-----accu_train: 76.9-----accu_test: 77.9\n",
            "epoch: 37-----cost: 0.8200282941596438-----accu_train: 76.8-----accu_test: 77.1\n",
            "epoch: 38-----cost: 0.7893377173442487-----accu_train: 77.8-----accu_test: 78.5\n",
            "epoch: 39-----cost: 0.7933205108087102-----accu_train: 77.0-----accu_test: 77.4\n",
            "epoch: 40-----cost: 0.76178353970196-----accu_train: 78.6-----accu_test: 79.1\n",
            "epoch: 41-----cost: 0.7673350240069088-----accu_train: 77.2-----accu_test: 77.5\n",
            "epoch: 42-----cost: 0.7368116588039456-----accu_train: 79.3-----accu_test: 79.8\n",
            "epoch: 43-----cost: 0.7427520043499232-----accu_train: 77.4-----accu_test: 77.8\n",
            "epoch: 44-----cost: 0.7139565657790111-----accu_train: 80.0-----accu_test: 80.4\n",
            "epoch: 45-----cost: 0.7196321403802415-----accu_train: 77.8-----accu_test: 78.3\n",
            "epoch: 46-----cost: 0.6927955806625496-----accu_train: 80.7-----accu_test: 81.1\n",
            "epoch: 47-----cost: 0.6977483142749279-----accu_train: 78.3-----accu_test: 78.8\n",
            "epoch: 48-----cost: 0.6729884169255957-----accu_train: 81.3-----accu_test: 81.8\n",
            "epoch: 49-----cost: 0.6768907481898356-----accu_train: 78.9-----accu_test: 79.6\n",
            "epoch: 50-----cost: 0.6542948132901595-----accu_train: 81.9-----accu_test: 82.5\n",
            "epoch: 51-----cost: 0.6569838115074336-----accu_train: 79.6-----accu_test: 80.4\n",
            "epoch: 52-----cost: 0.636574447958229-----accu_train: 82.4-----accu_test: 83.0\n",
            "epoch: 53-----cost: 0.6380660083546316-----accu_train: 80.3-----accu_test: 81.3\n",
            "epoch: 54-----cost: 0.619772638503733-----accu_train: 82.9-----accu_test: 83.6\n",
            "epoch: 55-----cost: 0.620218792001958-----accu_train: 81.2-----accu_test: 82.2\n",
            "epoch: 56-----cost: 0.6038970014926929-----accu_train: 83.5-----accu_test: 84.0\n",
            "epoch: 57-----cost: 0.6035121451367201-----accu_train: 82.1-----accu_test: 82.8\n",
            "epoch: 58-----cost: 0.58898575607878-----accu_train: 83.9-----accu_test: 84.6\n",
            "epoch: 59-----cost: 0.5879776533919242-----accu_train: 82.9-----accu_test: 83.7\n",
            "epoch: 60-----cost: 0.5750705054622719-----accu_train: 84.4-----accu_test: 85.0\n",
            "epoch: 61-----cost: 0.5735974044694871-----accu_train: 83.7-----accu_test: 84.4\n",
            "epoch: 62-----cost: 0.562145196762162-----accu_train: 84.7-----accu_test: 85.4\n",
            "epoch: 63-----cost: 0.5603045255070637-----accu_train: 84.3-----accu_test: 85.3\n",
            "epoch: 64-----cost: 0.5501545716482223-----accu_train: 85.1-----accu_test: 85.9\n",
            "epoch: 65-----cost: 0.5479967997086712-----accu_train: 85.0-----accu_test: 85.8\n",
            "epoch: 66-----cost: 0.5390057427675328-----accu_train: 85.5-----accu_test: 86.3\n",
            "epoch: 67-----cost: 0.5365598643780863-----accu_train: 85.5-----accu_test: 86.3\n",
            "epoch: 68-----cost: 0.5285938719110544-----accu_train: 85.8-----accu_test: 86.6\n",
            "epoch: 69-----cost: 0.5258903160052483-----accu_train: 86.0-----accu_test: 86.7\n",
            "epoch: 70-----cost: 0.518827077407793-----accu_train: 86.0-----accu_test: 86.9\n",
            "epoch: 71-----cost: 0.5159096553247624-----accu_train: 86.4-----accu_test: 86.9\n",
            "epoch: 72-----cost: 0.509639815922136-----accu_train: 86.3-----accu_test: 87.2\n",
            "epoch: 73-----cost: 0.5065663428977223-----accu_train: 86.8-----accu_test: 87.2\n",
            "epoch: 74-----cost: 0.500993113721031-----accu_train: 86.6-----accu_test: 87.4\n",
            "epoch: 75-----cost: 0.4978293330849524-----accu_train: 87.0-----accu_test: 87.6\n",
            "epoch: 76-----cost: 0.49286668264306677-----accu_train: 86.9-----accu_test: 87.7\n",
            "epoch: 77-----cost: 0.48967850790863743-----accu_train: 87.3-----accu_test: 87.8\n",
            "epoch: 78-----cost: 0.4852490591752083-----accu_train: 87.1-----accu_test: 87.8\n",
            "epoch: 79-----cost: 0.48209607023316436-----accu_train: 87.6-----accu_test: 88.1\n",
            "epoch: 80-----cost: 0.478129543124333-----accu_train: 87.3-----accu_test: 88.0\n",
            "epoch: 81-----cost: 0.4750606615760485-----accu_train: 87.8-----accu_test: 88.2\n",
            "epoch: 82-----cost: 0.4714930927066466-----accu_train: 87.5-----accu_test: 88.2\n",
            "epoch: 83-----cost: 0.4685443647999576-----accu_train: 87.9-----accu_test: 88.4\n",
            "epoch: 84-----cost: 0.46531791548647145-----accu_train: 87.7-----accu_test: 88.4\n",
            "epoch: 85-----cost: 0.4625120816630212-----accu_train: 88.1-----accu_test: 88.6\n",
            "epoch: 86-----cost: 0.45957512176228343-----accu_train: 87.9-----accu_test: 88.5\n",
            "epoch: 87-----cost: 0.4569226445846877-----accu_train: 88.3-----accu_test: 88.7\n",
            "epoch: 88-----cost: 0.454229860675955-----accu_train: 88.1-----accu_test: 88.7\n",
            "epoch: 89-----cost: 0.45173104853700013-----accu_train: 88.3-----accu_test: 88.8\n",
            "epoch: 90-----cost: 0.4492434352912601-----accu_train: 88.2-----accu_test: 88.8\n",
            "epoch: 91-----cost: 0.4468912127985261-----accu_train: 88.4-----accu_test: 88.9\n",
            "epoch: 92-----cost: 0.444575892169462-----accu_train: 88.3-----accu_test: 89.0\n",
            "epoch: 93-----cost: 0.442358710777491-----accu_train: 88.5-----accu_test: 89.1\n",
            "epoch: 94-----cost: 0.4401885704281637-----accu_train: 88.4-----accu_test: 89.0\n",
            "epoch: 95-----cost: 0.438092995872283-----accu_train: 88.5-----accu_test: 89.1\n",
            "epoch: 96-----cost: 0.4360461614712508-----accu_train: 88.5-----accu_test: 89.2\n",
            "epoch: 97-----cost: 0.4340588246964916-----accu_train: 88.6-----accu_test: 89.2\n",
            "epoch: 98-----cost: 0.4321179982719282-----accu_train: 88.6-----accu_test: 89.2\n",
            "epoch: 99-----cost: 0.43022680044659817-----accu_train: 88.7-----accu_test: 89.2\n",
            "epoch: 100-----cost: 0.42837851510152425-----accu_train: 88.6-----accu_test: 89.3\n",
            "epoch: 101-----cost: 0.42657316067562767-----accu_train: 88.7-----accu_test: 89.3\n",
            "epoch: 102-----cost: 0.4248070155056991-----accu_train: 88.7-----accu_test: 89.3\n",
            "epoch: 103-----cost: 0.4230790574123967-----accu_train: 88.8-----accu_test: 89.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 104-----cost: 0.421386997608091-----accu_train: 88.8-----accu_test: 89.4\n",
            "epoch: 105-----cost: 0.41972960443405116-----accu_train: 88.8-----accu_test: 89.4\n",
            "epoch: 106-----cost: 0.41810529790563106-----accu_train: 88.8-----accu_test: 89.5\n",
            "epoch: 107-----cost: 0.41651291708612276-----accu_train: 88.9-----accu_test: 89.5\n",
            "epoch: 108-----cost: 0.4149512555122493-----accu_train: 88.9-----accu_test: 89.5\n",
            "epoch: 109-----cost: 0.41341928477683715-----accu_train: 88.9-----accu_test: 89.5\n",
            "epoch: 110-----cost: 0.41191601240970693-----accu_train: 89.0-----accu_test: 89.5\n",
            "epoch: 111-----cost: 0.41044053282251286-----accu_train: 89.0-----accu_test: 89.6\n",
            "epoch: 112-----cost: 0.4089919879367097-----accu_train: 89.0-----accu_test: 89.6\n",
            "epoch: 113-----cost: 0.40756957055243287-----accu_train: 89.0-----accu_test: 89.6\n",
            "epoch: 114-----cost: 0.40617251511103536-----accu_train: 89.1-----accu_test: 89.6\n",
            "epoch: 115-----cost: 0.40480009143808504-----accu_train: 89.1-----accu_test: 89.7\n",
            "epoch: 116-----cost: 0.4034516033606905-----accu_train: 89.1-----accu_test: 89.7\n",
            "epoch: 117-----cost: 0.4021263825797641-----accu_train: 89.2-----accu_test: 89.7\n",
            "epoch: 118-----cost: 0.40082378885893666-----accu_train: 89.2-----accu_test: 89.7\n",
            "epoch: 119-----cost: 0.3995432056541369-----accu_train: 89.2-----accu_test: 89.7\n",
            "epoch: 120-----cost: 0.39828404031561304-----accu_train: 89.2-----accu_test: 89.8\n",
            "epoch: 121-----cost: 0.39704572119013376-----accu_train: 89.3-----accu_test: 89.8\n",
            "epoch: 122-----cost: 0.395827697564937-----accu_train: 89.3-----accu_test: 89.8\n",
            "epoch: 123-----cost: 0.3946294377339858-----accu_train: 89.3-----accu_test: 89.8\n",
            "epoch: 124-----cost: 0.39345042872077457-----accu_train: 89.3-----accu_test: 89.8\n",
            "epoch: 125-----cost: 0.39229017492955653-----accu_train: 89.4-----accu_test: 89.8\n",
            "epoch: 126-----cost: 0.3911481977315705-----accu_train: 89.4-----accu_test: 89.8\n",
            "epoch: 127-----cost: 0.39002403446614253-----accu_train: 89.4-----accu_test: 89.9\n",
            "epoch: 128-----cost: 0.38891723796080896-----accu_train: 89.4-----accu_test: 89.9\n",
            "epoch: 129-----cost: 0.387827375746001-----accu_train: 89.4-----accu_test: 89.9\n",
            "epoch: 130-----cost: 0.3867540295564424-----accu_train: 89.4-----accu_test: 89.9\n",
            "epoch: 131-----cost: 0.3856967946822428-----accu_train: 89.4-----accu_test: 89.9\n",
            "epoch: 132-----cost: 0.38465527947976297-----accu_train: 89.5-----accu_test: 90.0\n",
            "epoch: 133-----cost: 0.3836291048153931-----accu_train: 89.5-----accu_test: 90.0\n",
            "epoch: 134-----cost: 0.38261790360081227-----accu_train: 89.5-----accu_test: 90.0\n",
            "epoch: 135-----cost: 0.38162132030420703-----accu_train: 89.5-----accu_test: 90.0\n",
            "epoch: 136-----cost: 0.38063901051657045-----accu_train: 89.5-----accu_test: 90.0\n",
            "epoch: 137-----cost: 0.37967064051524685-----accu_train: 89.6-----accu_test: 90.0\n",
            "epoch: 138-----cost: 0.37871588686315333-----accu_train: 89.6-----accu_test: 90.1\n",
            "epoch: 139-----cost: 0.3777744360151026-----accu_train: 89.6-----accu_test: 90.1\n",
            "epoch: 140-----cost: 0.3768459839493025-----accu_train: 89.6-----accu_test: 90.1\n",
            "epoch: 141-----cost: 0.37593023581001-----accu_train: 89.6-----accu_test: 90.1\n",
            "epoch: 142-----cost: 0.375026905569462-----accu_train: 89.6-----accu_test: 90.1\n",
            "epoch: 143-----cost: 0.3741357157021765-----accu_train: 89.7-----accu_test: 90.1\n",
            "epoch: 144-----cost: 0.3732563968750051-----accu_train: 89.7-----accu_test: 90.1\n",
            "epoch: 145-----cost: 0.3723886876494465-----accu_train: 89.7-----accu_test: 90.2\n",
            "epoch: 146-----cost: 0.37153233419741966-----accu_train: 89.7-----accu_test: 90.2\n",
            "epoch: 147-----cost: 0.3706870900286229-----accu_train: 89.7-----accu_test: 90.2\n",
            "epoch: 148-----cost: 0.3698527157297149-----accu_train: 89.7-----accu_test: 90.2\n",
            "epoch: 149-----cost: 0.36902897871421037-----accu_train: 89.8-----accu_test: 90.2\n",
            "epoch: 150-----cost: 0.3682156529829206-----accu_train: 89.8-----accu_test: 90.2\n",
            "epoch: 151-----cost: 0.3674125188942081-----accu_train: 89.8-----accu_test: 90.2\n",
            "epoch: 152-----cost: 0.3666193629437328-----accu_train: 89.8-----accu_test: 90.3\n",
            "epoch: 153-----cost: 0.36583597755314784-----accu_train: 89.8-----accu_test: 90.3\n",
            "epoch: 154-----cost: 0.36506216086738374-----accu_train: 89.9-----accu_test: 90.3\n",
            "epoch: 155-----cost: 0.36429771656008475-----accu_train: 89.9-----accu_test: 90.3\n",
            "epoch: 156-----cost: 0.3635424536468398-----accu_train: 89.9-----accu_test: 90.3\n",
            "epoch: 157-----cost: 0.3627961863058384-----accu_train: 89.9-----accu_test: 90.3\n",
            "epoch: 158-----cost: 0.3620587337056197-----accu_train: 89.9-----accu_test: 90.3\n",
            "epoch: 159-----cost: 0.36132991983958535-----accu_train: 89.9-----accu_test: 90.3\n",
            "epoch: 160-----cost: 0.36060957336697785-----accu_train: 89.9-----accu_test: 90.3\n",
            "epoch: 161-----cost: 0.3598975274600295-----accu_train: 90.0-----accu_test: 90.3\n",
            "epoch: 162-----cost: 0.3591936196570099-----accu_train: 90.0-----accu_test: 90.4\n",
            "epoch: 163-----cost: 0.3584976917209091-----accu_train: 90.0-----accu_test: 90.4\n",
            "epoch: 164-----cost: 0.35780958950351044-----accu_train: 90.0-----accu_test: 90.4\n",
            "epoch: 165-----cost: 0.35712916281461465-----accu_train: 90.0-----accu_test: 90.4\n",
            "epoch: 166-----cost: 0.3564562652961946-----accu_train: 90.0-----accu_test: 90.4\n",
            "epoch: 167-----cost: 0.35579075430126383-----accu_train: 90.0-----accu_test: 90.4\n",
            "epoch: 168-----cost: 0.35513249077726056-----accu_train: 90.0-----accu_test: 90.5\n",
            "epoch: 169-----cost: 0.35448133915374963-----accu_train: 90.1-----accu_test: 90.5\n",
            "epoch: 170-----cost: 0.3538371672342652-----accu_train: 90.1-----accu_test: 90.5\n",
            "epoch: 171-----cost: 0.3531998460921111-----accu_train: 90.1-----accu_test: 90.5\n",
            "epoch: 172-----cost: 0.35256924996996186-----accu_train: 90.1-----accu_test: 90.5\n",
            "epoch: 173-----cost: 0.3519452561830981-----accu_train: 90.1-----accu_test: 90.5\n",
            "epoch: 174-----cost: 0.3513277450261311-----accu_train: 90.1-----accu_test: 90.5\n",
            "epoch: 175-----cost: 0.3507165996830679-----accu_train: 90.1-----accu_test: 90.5\n",
            "epoch: 176-----cost: 0.35011170614058323-----accu_train: 90.1-----accu_test: 90.6\n",
            "epoch: 177-----cost: 0.349512953104366-----accu_train: 90.1-----accu_test: 90.6\n",
            "epoch: 178-----cost: 0.3489202319184149-----accu_train: 90.2-----accu_test: 90.6\n",
            "epoch: 179-----cost: 0.34833343648716547-----accu_train: 90.2-----accu_test: 90.6\n",
            "epoch: 180-----cost: 0.34775246320033326-----accu_train: 90.2-----accu_test: 90.6\n",
            "epoch: 181-----cost: 0.3471772108603661-----accu_train: 90.2-----accu_test: 90.6\n",
            "epoch: 182-----cost: 0.3466075806124006-----accu_train: 90.2-----accu_test: 90.6\n",
            "epoch: 183-----cost: 0.34604347587662354-----accu_train: 90.2-----accu_test: 90.6\n",
            "epoch: 184-----cost: 0.3454848022829455-----accu_train: 90.2-----accu_test: 90.6\n",
            "epoch: 185-----cost: 0.3449314676078947-----accu_train: 90.2-----accu_test: 90.6\n",
            "epoch: 186-----cost: 0.3443833817136431-----accu_train: 90.3-----accu_test: 90.6\n",
            "epoch: 187-----cost: 0.3438404564890859-----accu_train: 90.3-----accu_test: 90.6\n",
            "epoch: 188-----cost: 0.34330260579289223-----accu_train: 90.3-----accu_test: 90.7\n",
            "epoch: 189-----cost: 0.3427697453984531-----accu_train: 90.3-----accu_test: 90.7\n",
            "epoch: 190-----cost: 0.3422417929406514-----accu_train: 90.3-----accu_test: 90.7\n",
            "epoch: 191-----cost: 0.3417186678643907-----accu_train: 90.3-----accu_test: 90.7\n",
            "epoch: 192-----cost: 0.34120029137480656-----accu_train: 90.3-----accu_test: 90.7\n",
            "epoch: 193-----cost: 0.3406865863891107-----accu_train: 90.4-----accu_test: 90.7\n",
            "epoch: 194-----cost: 0.3401774774899913-----accu_train: 90.4-----accu_test: 90.7\n",
            "epoch: 195-----cost: 0.33967289088052494-----accu_train: 90.4-----accu_test: 90.7\n",
            "epoch: 196-----cost: 0.3391727543405365-----accu_train: 90.4-----accu_test: 90.7\n",
            "epoch: 197-----cost: 0.338676997184355-----accu_train: 90.4-----accu_test: 90.7\n",
            "epoch: 198-----cost: 0.33818555021991553-----accu_train: 90.4-----accu_test: 90.7\n",
            "epoch: 199-----cost: 0.3376983457091582-----accu_train: 90.4-----accu_test: 90.7\n",
            "epoch: 200-----cost: 0.3372153173296735-----accu_train: 90.4-----accu_test: 90.7\n",
            "epoch: 201-----cost: 0.3367364001375539-----accu_train: 90.4-----accu_test: 90.8\n",
            "epoch: 202-----cost: 0.33626153053140523-----accu_train: 90.5-----accu_test: 90.7\n",
            "epoch: 203-----cost: 0.3357906462174747-----accu_train: 90.5-----accu_test: 90.7\n",
            "epoch: 204-----cost: 0.3353236861758612-----accu_train: 90.5-----accu_test: 90.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 205-----cost: 0.3348605906277631-----accu_train: 90.5-----accu_test: 90.8\n",
            "epoch: 206-----cost: 0.33440130100373067-----accu_train: 90.5-----accu_test: 90.8\n",
            "epoch: 207-----cost: 0.33394575991288783-----accu_train: 90.5-----accu_test: 90.8\n",
            "epoch: 208-----cost: 0.3334939111130853-----accu_train: 90.5-----accu_test: 90.8\n",
            "epoch: 209-----cost: 0.33304569948195917-----accu_train: 90.5-----accu_test: 90.8\n",
            "epoch: 210-----cost: 0.33260107098885755-----accu_train: 90.6-----accu_test: 90.8\n",
            "epoch: 211-----cost: 0.3321599726676066-----accu_train: 90.6-----accu_test: 90.8\n",
            "epoch: 212-----cost: 0.3317223525900904-----accu_train: 90.6-----accu_test: 90.8\n",
            "epoch: 213-----cost: 0.3312881598406132-----accu_train: 90.6-----accu_test: 90.9\n",
            "epoch: 214-----cost: 0.33085734449101695-----accu_train: 90.6-----accu_test: 90.9\n",
            "epoch: 215-----cost: 0.33042985757653204-----accu_train: 90.6-----accu_test: 90.9\n",
            "epoch: 216-----cost: 0.3300056510723337-----accu_train: 90.6-----accu_test: 90.9\n",
            "epoch: 217-----cost: 0.32958467787077983-----accu_train: 90.6-----accu_test: 90.9\n",
            "epoch: 218-----cost: 0.32916689175930974-----accu_train: 90.7-----accu_test: 90.9\n",
            "epoch: 219-----cost: 0.32875224739897874-----accu_train: 90.7-----accu_test: 90.9\n",
            "epoch: 220-----cost: 0.3283407003036126-----accu_train: 90.7-----accu_test: 90.9\n",
            "epoch: 221-----cost: 0.3279322068195533-----accu_train: 90.7-----accu_test: 90.9\n",
            "epoch: 222-----cost: 0.32752672410598377-----accu_train: 90.7-----accu_test: 91.0\n",
            "epoch: 223-----cost: 0.3271242101158111-----accu_train: 90.7-----accu_test: 91.0\n",
            "epoch: 224-----cost: 0.32672462357708587-----accu_train: 90.7-----accu_test: 91.0\n",
            "epoch: 225-----cost: 0.326327923974945-----accu_train: 90.7-----accu_test: 91.0\n",
            "epoch: 226-----cost: 0.32593407153405946-----accu_train: 90.7-----accu_test: 91.0\n",
            "epoch: 227-----cost: 0.32554302720156925-----accu_train: 90.7-----accu_test: 91.0\n",
            "epoch: 228-----cost: 0.32515475263049237-----accu_train: 90.7-----accu_test: 91.0\n",
            "epoch: 229-----cost: 0.3247692101635901-----accu_train: 90.8-----accu_test: 91.0\n",
            "epoch: 230-----cost: 0.3243863628176767-----accu_train: 90.8-----accu_test: 91.1\n",
            "epoch: 231-----cost: 0.3240061742683565-----accu_train: 90.8-----accu_test: 91.1\n",
            "epoch: 232-----cost: 0.3236286088351778-----accu_train: 90.8-----accu_test: 91.1\n",
            "epoch: 233-----cost: 0.3232536314671882-----accu_train: 90.8-----accu_test: 91.1\n",
            "epoch: 234-----cost: 0.32288120772887974-----accu_train: 90.8-----accu_test: 91.1\n",
            "epoch: 235-----cost: 0.3225113037865122-----accu_train: 90.8-----accu_test: 91.2\n",
            "epoch: 236-----cost: 0.3221438863948018-----accu_train: 90.8-----accu_test: 91.2\n",
            "epoch: 237-----cost: 0.32177892288396365-----accu_train: 90.9-----accu_test: 91.2\n",
            "epoch: 238-----cost: 0.32141638114709953-----accu_train: 90.9-----accu_test: 91.2\n",
            "epoch: 239-----cost: 0.32105622962791674-----accu_train: 90.9-----accu_test: 91.2\n",
            "epoch: 240-----cost: 0.320698437308771-----accu_train: 90.9-----accu_test: 91.2\n",
            "epoch: 241-----cost: 0.32034297369902265-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 242-----cost: 0.3199898088236945-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 243-----cost: 0.3196389132124267-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 244-----cost: 0.3192902578887146-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 245-----cost: 0.3189438143594248-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 246-----cost: 0.3185995546045806-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 247-----cost: 0.3182574510674056-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 248-----cost: 0.31791747664462355-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 249-----cost: 0.3175796046770015-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 250-----cost: 0.31724380894013177-----accu_train: 90.9-----accu_test: 91.3\n",
            "epoch: 251-----cost: 0.31691006363544466-----accu_train: 90.9-----accu_test: 91.4\n",
            "epoch: 252-----cost: 0.3165783433814479-----accu_train: 90.9-----accu_test: 91.4\n",
            "epoch: 253-----cost: 0.3162486232051818-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 254-----cost: 0.31592087853388684-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 255-----cost: 0.315595085186878-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 256-----cost: 0.31527121936761837-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 257-----cost: 0.3149492576559846-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 258-----cost: 0.3146291770007253-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 259-----cost: 0.31431095471209874-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 260-----cost: 0.31399456845469054-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 261-----cost: 0.31367999624040455-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 262-----cost: 0.31336721642161985-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 263-----cost: 0.3130562076845147-----accu_train: 91.0-----accu_test: 91.4\n",
            "epoch: 264-----cost: 0.3127469490425459-----accu_train: 91.0-----accu_test: 91.5\n",
            "epoch: 265-----cost: 0.31243941983008555-----accu_train: 91.0-----accu_test: 91.5\n",
            "epoch: 266-----cost: 0.3121335996962056-----accu_train: 91.0-----accu_test: 91.5\n",
            "epoch: 267-----cost: 0.3118294685986113-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 268-----cost: 0.31152700679771456-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 269-----cost: 0.31122619485084646-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 270-----cost: 0.31092701360660446-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 271-----cost: 0.31062944419933036-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 272-----cost: 0.31033346804371625-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 273-----cost: 0.3100390668295323-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 274-----cost: 0.30974622251647776-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 275-----cost: 0.3094549173291489-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 276-----cost: 0.3091651337521194-----accu_train: 91.1-----accu_test: 91.6\n",
            "epoch: 277-----cost: 0.30887685452513375-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 278-----cost: 0.30859006263840905-----accu_train: 91.1-----accu_test: 91.5\n",
            "epoch: 279-----cost: 0.3083047413280416-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 280-----cost: 0.30802087407151624-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 281-----cost: 0.30773844458331645-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 282-----cost: 0.3074574368106315-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 283-----cost: 0.3071778349291582-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 284-----cost: 0.3068996233389957-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 285-----cost: 0.3066227866606308-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 286-----cost: 0.3063473097310097-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 287-----cost: 0.3060731775996972-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 288-----cost: 0.3058003755251173-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 289-----cost: 0.30552888897087704-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 290-----cost: 0.3052587036021683-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 291-----cost: 0.3049898052822475-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 292-----cost: 0.3047221800689905-----accu_train: 91.2-----accu_test: 91.6\n",
            "epoch: 293-----cost: 0.3044558142115201-----accu_train: 91.2-----accu_test: 91.7\n",
            "epoch: 294-----cost: 0.3041906941469073-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 295-----cost: 0.3039268064969399-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 296-----cost: 0.30366413806496106-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 297-----cost: 0.30340267583277414-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 298-----cost: 0.30314240695761036-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 299-----cost: 0.30288331876916313-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 300-----cost: 0.302625398766681-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 301-----cost: 0.3023686346161223-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 302-----cost: 0.30211301414736885-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 303-----cost: 0.30185852535149593-----accu_train: 91.3-----accu_test: 91.7\n",
            "epoch: 304-----cost: 0.3016051563780984-----accu_train: 91.3-----accu_test: 91.8\n",
            "epoch: 305-----cost: 0.3013528955326732-----accu_train: 91.3-----accu_test: 91.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 306-----cost: 0.3011017312740523-----accu_train: 91.3-----accu_test: 91.8\n",
            "epoch: 307-----cost: 0.30085165221189003-----accu_train: 91.3-----accu_test: 91.8\n",
            "epoch: 308-----cost: 0.3006026471041999-----accu_train: 91.3-----accu_test: 91.8\n",
            "epoch: 309-----cost: 0.30035470485494226-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 310-----cost: 0.30010781451165897-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 311-----cost: 0.29986196526315667-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 312-----cost: 0.29961714643723525-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 313-----cost: 0.29937334749846256-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 314-----cost: 0.29913055804599264-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 315-----cost: 0.29888876781142576-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 316-----cost: 0.2986479666567137-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 317-----cost: 0.29840814457210296-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 318-----cost: 0.2981692916741194-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 319-----cost: 0.2979313982035928-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 320-----cost: 0.2976944545237188-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 321-----cost: 0.29745845111815905-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 322-----cost: 0.2972233785891765-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 323-----cost: 0.29698922765580943-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 324-----cost: 0.2967559891520769-----accu_train: 91.4-----accu_test: 91.8\n",
            "epoch: 325-----cost: 0.2965236540252214-----accu_train: 91.5-----accu_test: 91.8\n",
            "epoch: 326-----cost: 0.2962922133339835-----accu_train: 91.5-----accu_test: 91.8\n",
            "epoch: 327-----cost: 0.29606165824690944-----accu_train: 91.5-----accu_test: 91.8\n",
            "epoch: 328-----cost: 0.2958319800406909-----accu_train: 91.5-----accu_test: 91.8\n",
            "epoch: 329-----cost: 0.29560317009853515-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 330-----cost: 0.29537521990856846-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 331-----cost: 0.2951481210622655-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 332-----cost: 0.29492186525291125-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 333-----cost: 0.29469644427409-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 334-----cost: 0.2944718500182024-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 335-----cost: 0.29424807447501095-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 336-----cost: 0.29402510973021084-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 337-----cost: 0.29380294796402806-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 338-----cost: 0.29358158144984237-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 339-----cost: 0.2933610025528364-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 340-----cost: 0.2931412037286682-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 341-----cost: 0.29292217752216826-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 342-----cost: 0.292703916566061-----accu_train: 91.5-----accu_test: 91.9\n",
            "epoch: 343-----cost: 0.29248641357970717-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 344-----cost: 0.29226966136787075-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 345-----cost: 0.2920536528195074-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 346-----cost: 0.2918383809065733-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 347-----cost: 0.2916238386828573-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 348-----cost: 0.29141001928283206-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 349-----cost: 0.2911969159205254-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 350-----cost: 0.2909845218884132-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 351-----cost: 0.2907728305563294-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 352-----cost: 0.29056183537039776-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 353-----cost: 0.29035152985197854-----accu_train: 91.6-----accu_test: 91.9\n",
            "epoch: 354-----cost: 0.290141907596638-----accu_train: 91.6-----accu_test: 92.0\n",
            "epoch: 355-----cost: 0.2899329622731315-----accu_train: 91.6-----accu_test: 92.0\n",
            "epoch: 356-----cost: 0.28972468762240666-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 357-----cost: 0.2895170774566236-----accu_train: 91.6-----accu_test: 92.0\n",
            "epoch: 358-----cost: 0.2893101256581898-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 359-----cost: 0.28910382617881497-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 360-----cost: 0.288898173038578-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 361-----cost: 0.28869316032501297-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 362-----cost: 0.2884887821922096-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 363-----cost: 0.28828503285992757-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 364-----cost: 0.2880819066127276-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 365-----cost: 0.28787939779911587-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 366-----cost: 0.2876775008307035-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 367-----cost: 0.2874762101813793-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 368-----cost: 0.28727552038649606-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 369-----cost: 0.2870754260420722-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 370-----cost: 0.2868759218040034-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 371-----cost: 0.28667700238728977-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 372-----cost: 0.2864786625652743-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 373-----cost: 0.28628089716889504-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 374-----cost: 0.2860837010859474-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 375-----cost: 0.2858870692603599-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 376-----cost: 0.28569099669148146-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 377-----cost: 0.2854954784333798-----accu_train: 91.7-----accu_test: 92.0\n",
            "epoch: 378-----cost: 0.2853005095941507-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 379-----cost: 0.28510608533523935-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 380-----cost: 0.2849122008707714-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 381-----cost: 0.2847188514668952-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 382-----cost: 0.2845260324411343-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 383-----cost: 0.2843337391617503-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 384-----cost: 0.284141967047115-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 385-----cost: 0.2839507115650935-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 386-----cost: 0.28375996823243554-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 387-----cost: 0.283569732614178-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 388-----cost: 0.28338000032305427-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 389-----cost: 0.2831907670189152-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 390-----cost: 0.28300202840815764-----accu_train: 91.8-----accu_test: 92.0\n",
            "epoch: 391-----cost: 0.28281378024316073-----accu_train: 91.8-----accu_test: 92.1\n",
            "epoch: 392-----cost: 0.28262601832173345-----accu_train: 91.8-----accu_test: 92.1\n",
            "epoch: 393-----cost: 0.28243873848656814-----accu_train: 91.8-----accu_test: 92.1\n",
            "epoch: 394-----cost: 0.28225193662470327-----accu_train: 91.8-----accu_test: 92.1\n",
            "epoch: 395-----cost: 0.2820656086669944-----accu_train: 91.8-----accu_test: 92.1\n",
            "epoch: 396-----cost: 0.2818797505875923-----accu_train: 91.8-----accu_test: 92.1\n",
            "epoch: 397-----cost: 0.28169435840342993-----accu_train: 91.8-----accu_test: 92.1\n",
            "epoch: 398-----cost: 0.28150942817371627-----accu_train: 91.8-----accu_test: 92.1\n",
            "epoch: 399-----cost: 0.2813249559994381-----accu_train: 91.8-----accu_test: 92.1\n",
            "epoch: 400-----cost: 0.28114093802286894-----accu_train: 91.9-----accu_test: 92.1\n",
            "epoch: 401-----cost: 0.28095737042708513-----accu_train: 91.9-----accu_test: 92.1\n",
            "epoch: 402-----cost: 0.28077424943548895-----accu_train: 91.9-----accu_test: 92.1\n",
            "epoch: 403-----cost: 0.28059157131133894-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 404-----cost: 0.2804093323572878-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 405-----cost: 0.2802275289149249-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 406-----cost: 0.2800461573643275-----accu_train: 91.9-----accu_test: 92.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 407-----cost: 0.279865214123617-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 408-----cost: 0.2796846956485229-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 409-----cost: 0.27950459843195186-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 410-----cost: 0.2793249190035626-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 411-----cost: 0.2791456539293488-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 412-----cost: 0.27896679981122524-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 413-----cost: 0.27878835328662227-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 414-----cost: 0.2786103110280832-----accu_train: 91.9-----accu_test: 92.2\n",
            "epoch: 415-----cost: 0.2784326697428707-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 416-----cost: 0.2782554261725752-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 417-----cost: 0.2780785770927316-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 418-----cost: 0.27790211931243874-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 419-----cost: 0.2777260496739866-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 420-----cost: 0.27755036505248615-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 421-----cost: 0.2773750623555064-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 422-----cost: 0.2772001385227144-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 423-----cost: 0.2770255905255221-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 424-----cost: 0.27685141536673635-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 425-----cost: 0.2766776100802137-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 426-----cost: 0.27650417173052155-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 427-----cost: 0.27633109741260137-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 428-----cost: 0.276158384251438-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 429-----cost: 0.27598602940173295-----accu_train: 92.0-----accu_test: 92.2\n",
            "epoch: 430-----cost: 0.2758140300475812-----accu_train: 92.0-----accu_test: 92.3\n",
            "epoch: 431-----cost: 0.27564238340215436-----accu_train: 92.0-----accu_test: 92.3\n",
            "epoch: 432-----cost: 0.27547108670738435-----accu_train: 92.0-----accu_test: 92.3\n",
            "epoch: 433-----cost: 0.2753001372336552-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 434-----cost: 0.27512953227949594-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 435-----cost: 0.2749592691712792-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 436-----cost: 0.27478934526292154-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 437-----cost: 0.2746197579355908-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 438-----cost: 0.27445050459741377-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 439-----cost: 0.2742815826831903-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 440-----cost: 0.27411298965410896-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 441-----cost: 0.2739447229974672-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 442-----cost: 0.2737767802263962-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 443-----cost: 0.2736091588795858-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 444-----cost: 0.27344185652101727-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 445-----cost: 0.2732748707396949-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 446-----cost: 0.27310819914938445-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 447-----cost: 0.2729418393883532-----accu_train: 92.1-----accu_test: 92.3\n",
            "epoch: 448-----cost: 0.27277578911911265-----accu_train: 92.1-----accu_test: 92.4\n",
            "epoch: 449-----cost: 0.2726100460281659-----accu_train: 92.1-----accu_test: 92.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBQKuYh4HQTB"
      },
      "source": [
        "# Highest accuracy on test\n",
        "\n",
        "## epoch: 449-----cost: 0.2726100460281659-----accu_train: 92.1-----accu_test: 92.4\n",
        "\n",
        "\n"
      ]
    }
  ]
}